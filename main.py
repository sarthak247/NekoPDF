"""
Filename: main.py
Description: Implements endpoints for NekoPDF frontend to interact with
Run: uvicorn main:app --reload
"""
from typing import List
from fastapi import FastAPI
from pydantic import BaseModel
from llama_chat import get_llama_embeddings, get_llama_answers
from openai_chat import get_openai_answers, get_openai_embeddings

app = FastAPI()

class QA(BaseModel):
    """
    QA Class used by methods for accepting and validating HTTP data transfer
    Parameters:
        chunks: Chunks of text to embed
        store_name: Name of the vectorstore from which to load or save to
        query: Query to be run on the vectorstore
        k: Top K similarity search
    """
    chunks : List
    store_name : str
    query : str
    k: int

@app.post('/qa/openai')
def openai_response(inputs: QA):
    """
    Parameters:
        inputs: Instance of QA class used to accept inputs for generating response
    Returns: Response generated by OpenAI
    """
    vectorstore = get_openai_embeddings(inputs.chunks, inputs.store_name)
    if input.query:
        response = get_openai_answers(vectorstore, inputs.query, inputs.k)
        return response

@app.post('/qa/llama')
def llama_response(inputs: QA):
    """
    Parameters:
        inputs: Instance of QA class used to accept inputs for generating response
    Returns: Response generated by Llama
    """
    vectorstore = get_llama_embeddings(inputs.chunks, inputs.store_name)
    if input.query:
        response = get_llama_answers(vectorstore, inputs.query, inputs.k)
        return response
